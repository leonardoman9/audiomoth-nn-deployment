# üéØ **GUIDA COMPLETA: DEPLOYMENT NEURAL NETWORK SU AUDIOMOTH**
## *Da 32KB RAM a Modelli GRU-64 con Flash-Resident Tensor Store*

---

## **‚ö†Ô∏è DISCLAIMER IMPORTANTE**

**Terminologia**: Questa guida usa "Virtual Memory" e "Swapping" per analogia con sistemi desktop, ma l'implementazione √® un **Flash-resident tensor store con RAM cache**. Non c'√® MMU n√© paging hardware.

**Policy Critica**: **ZERO SCRITTURE FLASH A RUNTIME**. Flash √® read-only per pesi/modelli. Attivazioni e scratch restano in RAM.

---

## **üìö INDICE**

1. [Introduzione e Problema](#1-introduzione-e-problema)
2. [Hardware e Limitazioni](#2-hardware-e-limitazioni)
3. [Concetti Fondamentali](#3-concetti-fondamentali)
4. [Architettura della Soluzione](#4-architettura-della-soluzione)
5. [Implementazione Dettagliata](#5-implementazione-dettagliata)
6. [Problemi Incontrati e Soluzioni](#6-problemi-incontrati-e-soluzioni)
7. [Risultati e Performance](#7-risultati-e-performance)
8. [Guida all'Uso](#8-guida-alluso)
9. [Troubleshooting](#9-troubleshooting)
10. [Conclusioni](#10-conclusioni)

---

## **1. INTRODUZIONE E PROBLEMA**

### **1.1 Il Contesto**

L'**AudioMoth** √® un dispositivo di monitoraggio audio low-cost sviluppato per ricerca biologica e conservazione. Dotato del microcontrollore **EFM32WG380F256**, ha risorse computazionali molto limitate ma sufficienti per registrazione audio continua.

### **1.2 L'Obiettivo**

Implementare un sistema di **classificazione audio in tempo reale** per riconoscimento di specie di uccelli utilizzando una rete neurale **GRU-64** con:

- **Input**: Spettrogrammi [18√ó40] (18 frame temporali √ó 40 frequenze mel)
- **Hidden State**: 64 dimensioni
- **Output**: 35 classi di specie
- **Requisiti**: Inferenza real-time senza connessione cloud

### **1.3 Il Problema Fondamentale**

```
MODELLO RICHIESTO: ~40KB di memoria arena
HARDWARE DISPONIBILE: 32KB RAM totale
RISULTATO: IMPOSSIBILE con approccio tradizionale ‚ùå
```

---

## **2. HARDWARE E LIMITAZIONI**

### **2.1 Specifiche AudioMoth**

| Componente | Specifica | Limitazione |
|------------|-----------|-------------|
| **MCU** | EFM32WG380F256 | ARM Cortex-M4 |
| **RAM** | 32KB | Memoria principale limitata |
| **Flash** | 256KB | Storage read-only |
| **Clock** | 48MHz | Velocit√† di calcolo limitata |
| **FPU** | Single precision | Supporto floating point |

### **2.2 Memory Layout Tradizionale**

```
FLASH (256KB):
‚îú‚îÄ‚îÄ 0x0000-0x4000: Bootloader (16KB)
‚îú‚îÄ‚îÄ 0x4000-0x40000: Firmware (~240KB)
‚îî‚îÄ‚îÄ Modelli NN: Memorizzati come const arrays

RAM (32KB):
‚îú‚îÄ‚îÄ .text: Codice in esecuzione
‚îú‚îÄ‚îÄ .data: Variabili inizializzate  
‚îú‚îÄ‚îÄ .bss: Variabili non inizializzate
‚îú‚îÄ‚îÄ Heap: Allocazioni dinamiche
‚îî‚îÄ‚îÄ Stack: Chiamate funzioni e variabili locali
```

### **2.3 Il Limite Critico: .bss Section**

**SCOPERTA FONDAMENTALE**: Il sistema AudioMoth ha un limite critico a **4KB per la sezione .bss**.

#### **Cos'√® la .bss Section?**

La **.bss** (Block Started by Symbol) √® una sezione di memoria per variabili:
- **Non inizializzate** (o inizializzate a zero)
- **Statiche** o **globali**
- **Allocate automaticamente** all'avvio del programma

```c
// Queste vanno in .bss:
static uint8_t buffer[1024];        // 1KB in .bss
uint8_t global_array[2048];         // 2KB in .bss
static float weights[1000];         // 4KB in .bss

// Queste NON vanno in .bss:
const uint8_t rom_data[1024] = {...}; // In .text (Flash)
uint8_t* ptr = malloc(1024);           // In heap
uint8_t local_array[100];              // Nello stack
```

#### **Perch√© il Limite 4KB?**

Con `.bss > 4KB`, il sistema AudioMoth ha:
- **Stack overflow** durante l'allocazione tensori TFLM
- **Heap collision** con lo stack
- **Crash sistematici** in `VCMP_IRQHandler` o `0xDEADBEEE`

---

### **2.4 Cos'√® .bss, e differenza tra Stack e Heap**

- **.bss (Block Started by Symbol)**
  - Sezione della RAM che contiene variabili **globali o statiche non inizializzate** (o inizializzate a zero) allocate automaticamente all'avvio.
  - Esempi che finiscono in .bss:
    ```c
    static uint8_t buffer[1024];   // 1KB in .bss
    int global_array[256];         // ~1KB in .bss
    ```
  - Pro: semplice, zero overhead a runtime; Contro: occupa RAM fissa fin dall'avvio e riduce lo spazio per stack/heap.

- **Stack**
  - Area di RAM usata per chiamate di funzione, salvataggio registri di ritorno e **variabili locali** a durata automatica.
  - Cresce/decresce con le chiamate (LIFO). √à molto veloce ma di dimensione limitata.
  - Esempio (va nello stack):
    ```c
    void f(void) {
        uint8_t local[256];  // 256B sullo stack
    }
    ```
  - Rischi: array locali troppo grandi ‚Üí **stack overflow** (sintomi: crash/trap).

- **Heap**
  - Area di RAM usata per **allocazioni dinamiche** via `malloc/new` e rilasciate con `free/delete`.
  - Flessibile: si alloca solo quando serve; ma richiede gestione (frammentazione, check errori).
  - Esempio (va nell'heap):
    ```c
    uint8_t* p = malloc(4096);  // 4KB nell'heap
    // ...
    free(p);
    ```
  - Vantaggio chiave nel nostro caso: spostare grandi buffer da .bss ‚Üí **heap** riduce la pressione sulla .bss (critica <4KB) e lascia pi√π respiro allo stack.

In sintesi: mantenere **.bss < 4KB** √® fondamentale su AudioMoth; per buffer grandi preferire **heap** o allocazioni su stack (se piccole e a vita breve). Evitare grandi array locali su stack nelle funzioni ‚Äúcalde‚Äù dell'inferenza.

## **3. CONCETTI FONDAMENTALI**

### **3.1 TensorFlow Lite Micro (TFLM)**

**TFLM** √® la versione embedded di TensorFlow per microcontrollori:

#### **Come Funziona TFLM:**
```c
// 1. Creazione modello
TFLMModel model = tflm_create_model(model_data, size);

// 2. Creazione interprete con arena
uint8_t arena[20480];  // 20KB buffer
TFLMInterpreter interp = tflm_create_interpreter(model, arena, 20480);

// 3. Allocazione tensori
tflm_allocate_tensors(interp);  // Usa l'arena per tutti i tensori

// 4. Inferenza
float* input = tflm_get_input_data(interp, 0);
// ... riempi input ...
tflm_invoke(interp);
float* output = tflm_get_output_data(interp, 0);
```

#### **Problema dell'Arena:**
TFLM richiede un **buffer contiguo** (arena) per:
- Tensori di input
- Tensori di output  
- Tensori intermedi
- Metadati dell'interprete

Per GRU-64 [18√ó40]: **~40KB arena necessaria** > 32KB RAM disponibile!

### **3.2 Memory Swapping**

**Terminologia corretta**: Non √® vero "swapping" (non c'√® MMU), ma **Flash-resident tensor store con RAM cache**:
- Pesi/modelli **residenti in Flash** (read-only)
- **Cache LRU in RAM** per tensori attivi
- **Copy-on-access** da Flash ‚Üí RAM
- **NO scritture Flash** a runtime

#### **Esempio Concettuale:**
```
RAM (8KB):     [Tensor A] [Tensor B] [     ]
Flash (64KB):  [Tensor C] [Tensor D] [Tensor E] [Tensor F] ...

Quando serve Tensor C:
1. Evict Tensor A (meno usato) ‚Üí Flash
2. Load Tensor C da Flash ‚Üí RAM
3. RAM diventa: [Tensor C] [Tensor B] [     ]
```

### **3.3 LRU (Least Recently Used)**

**LRU** √® un algoritmo di cache che **evicts** (rimuove) i dati **meno recentemente usati**:

```c
typedef struct {
    uint32_t tensor_id;
    uint32_t last_access;    // Timestamp ultimo accesso
    bool in_ram;
} TensorInfo;

// Quando serve spazio:
uint32_t oldest_time = 0xFFFFFFFF;
uint32_t lru_tensor = 0;

for (int i = 0; i < num_tensors; i++) {
    if (tensors[i].in_ram && tensors[i].last_access < oldest_time) {
        oldest_time = tensors[i].last_access;
        lru_tensor = i;
    }
}
// Evict lru_tensor
```

### **3.4 Virtual Memory**

**Memoria Virtuale** √® un'astrazione che:
- Presenta uno **spazio di indirizzi** pi√π grande della RAM fisica
- **Mappa** indirizzi virtuali a posizioni fisiche (RAM o storage)
- **Trasparente** all'applicazione

#### **Nel Nostro Caso:**
```
Spazio Virtuale (64KB):   [Tensor 0] [Tensor 1] [Tensor 2] ...
                              ‚Üì         ‚Üì         ‚Üì
Mapping:                   RAM      Flash     Flash
Fisico:                  [0x2000]  [0x30000] [0x30800]
```

### **3.5 Linker Script**

Il **linker script** definisce come il linker:
- **Organizza** le sezioni di memoria
- **Assegna indirizzi** ai simboli
- **Mappa** codice e dati nella memoria fisica

#### **Esempio:**
```ld
MEMORY {
    FLASH (rx) : ORIGIN = 0x4000, LENGTH = 0x3C000    /* 240KB */
    RAM (rwx)  : ORIGIN = 0x20000000, LENGTH = 0x8000 /* 32KB */
}

SECTIONS {
    .text : {
        *(.text*)    /* Tutto il codice */
    } > FLASH
    
    .bss : {
        *(.bss*)     /* Variabili non inizializzate */
    } > RAM
}
```

---

## **4. ARCHITETTURA DELLA SOLUZIONE**

### **4.1 Approccio "Flash as External SRAM"**

Ispirato al suggerimento di **Gemini AI**, trattiamo la Flash interna come **External SRAM**:

```
TRADIZIONALE (con External SRAM):
MCU ‚Üí External SRAM Controller ‚Üí 8MB SRAM esterna
                                   ‚Üë
                            [Tensor Arena]

NOSTRO (Flash as External SRAM):  
MCU ‚Üí Flash Controller ‚Üí 256KB Flash interna
                           ‚Üë
                    [Virtual Arena]
```

### **4.2 Virtual Arena System**

Il **Virtual Arena System** √® composto da:

#### **4.2.1 Componenti Principali**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        APPLICAZIONE TFLM            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      TFLM WRAPPER VIRTUAL           ‚îÇ  ‚Üê Intercetta chiamate TFLM
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     VIRTUAL ARENA MANAGER           ‚îÇ  ‚Üê Gestisce memoria virtuale
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇRAM CACHE ‚îÇ         ‚îÇ FLASH STORAGE  ‚îÇ
‚îÇ   8KB    ‚îÇ ‚Üêswap‚Üí  ‚îÇ     64KB       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **4.2.2 Strutture Dati**

```c
// Metadati per ogni tensore virtuale
typedef struct {
    uint32_t id;              // ID univoco
    uint32_t size;            // Dimensione in bytes
    uint32_t flash_offset;    // Offset nella Flash arena
    uint8_t* ram_addr;        // Indirizzo RAM (se caricato)
    bool in_ram;              // true = in RAM, false = in Flash
    bool is_const;            // true = peso read-only, false = attivazione
    bool pinned;              // Non pu√≤ essere evicted
    uint32_t last_access;     // Per algoritmo LRU
    char name[32];            // Nome per debug
} VirtualTensor_t;

// Gestore globale dell'arena virtuale
typedef struct {
    VirtualTensor_t tensors[MAX_VIRTUAL_TENSORS];
    uint8_t* ram_cache;       // Pool RAM per tensori attivi
    uint32_t ram_used;        // RAM attualmente utilizzata
    uint32_t num_tensors;     // Numero di tensori allocati
    uint32_t access_counter;  // Contatore per LRU
} VirtualArenaManager_t;
```

### **4.3 Linker Script Modificato**

Per implementare "Flash as External SRAM":

```ld
MEMORY {
    FLASH_CODE (rx) : ORIGIN = 0x4000, LENGTH = 0x2C000   /* 176KB firmware */
    FLASH_ARENA (r) : ORIGIN = 0x30000, LENGTH = 0x10000  /* 64KB virtual */
    RAM (rwx)       : ORIGIN = 0x20000000, LENGTH = 0x8000 /* 32KB RAM */
}

SECTIONS {
    /* Sezione speciale per arena virtuale */
    .tensor_arena (NOLOAD): ALIGN(4) {
        . = ALIGN(4);
        __tensor_arena_start__ = .;
        . = . + 0x10000;  /* Riserva 64KB */
        __tensor_arena_end__ = .;
    } > FLASH_ARENA
}
```

**Simboli Generati:**
- `__tensor_arena_start__ = 0x30000`
- `__tensor_arena_end__ = 0x40000`
- **Spazio riservato**: 64KB per arena virtuale

---

## **5. IMPLEMENTAZIONE DETTAGLIATA**

### **5.1 Virtual Arena Manager**

#### **5.1.1 Inizializzazione**

```c
bool VirtualArena_Init(void) {
    // 1. Inizializza MSC (Memory System Controller) per Flash
    MSC_Init();
    
    // 2. Alloca RAM cache dal heap (evita .bss)
    ram_cache = (uint8_t*)malloc(RAM_CACHE_SIZE);
    if (!ram_cache) return false;
    
    // 3. Verifica simboli linker
    uint32_t flash_start = (uint32_t)&__tensor_arena_start__;
    uint32_t flash_end = (uint32_t)&__tensor_arena_end__;
    
    // 4. Fallback se simboli non definiti
    if ((flash_end - flash_start) == 0) {
        flash_start = 0x30000;
        flash_end = 0x40000;
    }
    
    // 5. Inizializza strutture dati
    memset(tensor_table, 0, sizeof(tensor_table));
    num_tensors = 0;
    ram_used = 0;
    access_counter = 0;
    
    return true;
}
```

#### **5.1.2 Allocazione Tensore Virtuale**

```c
uint32_t VirtualArena_AllocTensor(uint32_t size, const char* name) {
    if (num_tensors >= MAX_VIRTUAL_TENSORS) {
        return INVALID_TENSOR_ID;
    }
    
    // Trova spazio nella Flash arena
    static uint32_t flash_offset = 0;
    if (flash_offset + size > VIRTUAL_ARENA_SIZE) {
        return INVALID_TENSOR_ID;  // Arena piena
    }
    
    // Crea entry nella tabella
    VirtualTensor_t* tensor = &tensor_table[num_tensors];
    tensor->id = num_tensors;
    tensor->size = size;
    tensor->flash_offset = flash_offset;
    tensor->ram_addr = NULL;
    tensor->in_ram = false;
    tensor->dirty = false;
    tensor->pinned = false;
    tensor->last_access = 0;
    
    if (name) {
        strncpy(tensor->name, name, 31);
        tensor->name[31] = '\0';
    }
    
    flash_offset += size;
    num_tensors++;
    
    return tensor->id;
}
```

#### **5.1.3 Accesso Tensore (con Swap Automatico)**

```c
void* VirtualArena_GetTensor(uint32_t tensor_id) {
    if (tensor_id >= num_tensors) return NULL;
    
    VirtualTensor_t* tensor = &tensor_table[tensor_id];
    
    // Aggiorna timestamp per LRU
    tensor->last_access = access_counter++;
    
    // Se gi√† in RAM, restituisci direttamente
    if (tensor->in_ram) {
        return tensor->ram_addr;
    }
    
    // SWAP NECESSARIO: carica da Flash a RAM
    
    // 1. Controlla se c'√® spazio in RAM
    while (ram_used + tensor->size > RAM_CACHE_SIZE) {
        // Trova tensore LRU da evictare
        uint32_t lru_id = find_lru_tensor();
        if (lru_id == INVALID_TENSOR_ID) {
            return NULL;  // Nessun tensore evictable
        }
        evict_tensor(lru_id);
    }
    
    // 2. Alloca spazio RAM
    tensor->ram_addr = allocate_ram_space(tensor->size);
    
    // 3. Copia da Flash a RAM
    uint32_t flash_addr = (uint32_t)&__tensor_arena_start__ + tensor->flash_offset;
    memcpy(tensor->ram_addr, (void*)flash_addr, tensor->size);
    
    // 4. Aggiorna stato
    tensor->in_ram = true;
    ram_used += tensor->size;
    
    return tensor->ram_addr;
}
```

#### **5.1.4 Eviction Algorithm (LRU)**

```c
static uint32_t find_lru_tensor(void) {
    uint32_t lru_id = INVALID_TENSOR_ID;
    uint32_t min_access = 0xFFFFFFFF;
    
    for (uint32_t i = 0; i < num_tensors; i++) {
        VirtualTensor_t* t = &tensor_table[i];
        
        // Skip tensori non in RAM o pinnati
        if (!t->in_ram || t->pinned) continue;
        
        if (t->last_access < min_access) {
            min_access = t->last_access;
            lru_id = i;
        }
    }
    
    return lru_id;
}

static bool evict_tensor(uint32_t tensor_id) {
    VirtualTensor_t* tensor = &tensor_table[tensor_id];
    
    if (!tensor->in_ram || tensor->pinned) {
        return false;
    }
    
    // Se modificato, scrivi back in Flash
    if (tensor->dirty) {
        uint32_t flash_addr = (uint32_t)&__tensor_arena_start__ + 
                             tensor->flash_offset;
        
        // Cancella pagina Flash
        MSC_ErasePage((uint32_t*)flash_addr);
        
        // Scrivi dati aggiornati
        MSC_WriteWord((uint32_t*)flash_addr, tensor->ram_addr, tensor->size);
        
        tensor->dirty = false;
    }
    
    // Libera RAM
    ram_used -= tensor->size;
    tensor->ram_addr = NULL;
    tensor->in_ram = false;
    
    return true;
}
```

### **5.2 TFLM Wrapper Virtual**

#### **5.2.1 Struttura Interprete Virtuale**

```c
typedef struct {
    const unsigned char* model_data;
    
    // ID dei tensori virtuali invece di puntatori diretti
    uint32_t input_tensor_id;
    uint32_t output_tensor_id;
    uint32_t intermediate_tensor_ids[16];
    uint32_t num_intermediates;
    
    // Dimensioni
    int input_dims[4];
    int output_dims[4];
    
    bool allocated;
    bool is_backbone;
} VirtualInterpreter;
```

#### **5.2.2 Allocazione Tensori Virtuali**

```c
TFLMStatus tflm_allocate_tensors(TFLMInterpreter interpreter) {
    VirtualInterpreter* interp = (VirtualInterpreter*)interpreter;
    
    // Calcola dimensioni necessarie
    size_t input_size, output_size;
    
    if (interp->is_backbone) {
        // Backbone: [1, 18, 40] -> [1, 18, 32]
        input_size = 1 * 18 * 40 * sizeof(float);   // 2880 bytes
        output_size = 1 * 18 * 32 * sizeof(float);  // 2304 bytes
        
        // Alloca tensori intermedi per layers
        interp->intermediate_tensor_ids[0] = 
            VirtualArena_AllocTensor(4608, "backbone_conv1");  // [1,18,64]
        interp->intermediate_tensor_ids[1] = 
            VirtualArena_AllocTensor(2304, "backbone_pool1");  // [1,9,64]
        interp->intermediate_tensor_ids[2] = 
            VirtualArena_AllocTensor(1152, "backbone_conv2");  // [1,9,32]
        interp->num_intermediates = 3;
        
    } else {
        // Streaming GRU: [1, 32] -> [1, 32]
        input_size = 1 * 32 * sizeof(float);        // 128 bytes
        output_size = 1 * 32 * sizeof(float);       // 128 bytes
        
        // GRU hidden state
        interp->intermediate_tensor_ids[0] = 
            VirtualArena_AllocTensor(128, "gru_hidden");
        interp->num_intermediates = 1;
    }
    
    // Alloca tensori input/output principali
    interp->input_tensor_id = VirtualArena_AllocTensor(input_size, 
        interp->is_backbone ? "backbone_input" : "streaming_input");
    
    interp->output_tensor_id = VirtualArena_AllocTensor(output_size,
        interp->is_backbone ? "backbone_output" : "streaming_output");
    
    // Verifica allocazioni
    if (interp->input_tensor_id == INVALID_TENSOR_ID || 
        interp->output_tensor_id == INVALID_TENSOR_ID) {
        return TFLM_OUT_OF_MEMORY;
    }
    
    // Pin tensori critici per performance
    VirtualArena_PinTensor(interp->input_tensor_id);
    VirtualArena_PinTensor(interp->output_tensor_id);
    
    interp->allocated = true;
    return TFLM_OK;
}
```

#### **5.2.3 Accesso Tensori (Transparent Swapping)**

```c
float* tflm_get_input_data(TFLMInterpreter interpreter, int input_index) {
    if (!interpreter || input_index != 0) return NULL;
    
    VirtualInterpreter* interp = (VirtualInterpreter*)interpreter;
    if (!interp->allocated) return NULL;
    
    // Accesso trasparente: pu√≤ triggare swap da Flash a RAM
    return (float*)VirtualArena_GetTensor(interp->input_tensor_id);
}

float* tflm_get_output_data(TFLMInterpreter interpreter, int output_index) {
    if (!interpreter || output_index != 0) return NULL;
    
    VirtualInterpreter* interp = (VirtualInterpreter*)interpreter;
    if (!interp->allocated) return NULL;
    
    // Accesso trasparente: pu√≤ triggare swap da Flash a RAM
    return (float*)VirtualArena_GetTensor(interp->output_tensor_id);
}
```

#### **5.2.4 Inferenza con Virtual Memory**

```c
TFLMStatus tflm_invoke(TFLMInterpreter interpreter) {
    VirtualInterpreter* interp = (VirtualInterpreter*)interpreter;
    
    // 1. Carica input tensor (swap se necessario)
    float* input = (float*)VirtualArena_GetTensor(interp->input_tensor_id);
    if (!input) return TFLM_ERROR;
    
    // 2. Processa attraverso layers con swap intermedi
    for (uint32_t i = 0; i < interp->num_intermediates; i++) {
        // Carica tensore intermedio (pu√≤ fare swap)
        void* intermediate = VirtualArena_GetTensor(
            interp->intermediate_tensor_ids[i]);
        if (!intermediate) return TFLM_ERROR;
        
        // Simulazione layer processing
        // (In realt√† chiamerebbe kernels TFLM)
        
        // Marca come modificato per writeback
        VirtualArena_MarkDirty(interp->intermediate_tensor_ids[i]);
        
        // Unpin tensore precedente per permettere swap
        if (i > 0) {
            VirtualArena_UnpinTensor(interp->intermediate_tensor_ids[i-1]);
        }
    }
    
    // 3. Scrivi output finale
    float* output = (float*)VirtualArena_GetTensor(interp->output_tensor_id);
    if (!output) return TFLM_ERROR;
    
    // Simula computazione finale
    VirtualArena_MarkDirty(interp->output_tensor_id);
    
    return TFLM_OK;
}
```

### **5.3 Optimizzazione .bss**

#### **5.3.1 Problema delle Allocazioni Statiche**

```c
// PROBLEMATICO (va in .bss):
static uint8_t g_backbone_arena[8192];     // 8KB in .bss
static uint8_t g_streaming_arena[4096];    // 4KB in .bss
static float g_gru_hidden_state[64];       // 256B in .bss
static uint8_t ram_cache[8192];            // 8KB in .bss
static VirtualTensor_t tensor_table[64];   // ~5KB in .bss
                                           // TOTALE: ~25KB .bss ‚ùå
```

#### **5.3.2 Soluzione: Allocazione Dinamica**

```c
// SOLUZIONE (heap allocation):
static uint8_t* g_backbone_arena = NULL;
static uint8_t* g_streaming_arena = NULL;
static float* g_gru_hidden_state = NULL;

bool NN_Init(void) {
    // Alloca dal heap invece di .bss
    g_backbone_arena = (uint8_t*)malloc(6 * 1024);    // 6KB heap
    g_streaming_arena = (uint8_t*)malloc(3 * 1024);   // 3KB heap
    g_gru_hidden_state = (float*)malloc(64 * sizeof(float)); // 256B heap
    
    if (!g_backbone_arena || !g_streaming_arena || !g_gru_hidden_state) {
        // Cleanup in caso di fallimento
        if (g_backbone_arena) free(g_backbone_arena);
        if (g_streaming_arena) free(g_streaming_arena);
        if (g_gru_hidden_state) free(g_gru_hidden_state);
        return false;
    }
    
    // Clear memory
    memset(g_backbone_arena, 0, 6 * 1024);
    memset(g_streaming_arena, 0, 3 * 1024);
    memset(g_gru_hidden_state, 0, 64 * sizeof(float));
    
    return true;
}
```

**Risultato:**
- **.bss**: Da 25KB ‚Üí **2.6KB** ‚úÖ
- **Heap**: +17KB (ancora dentro 32KB totali)

---

## **6. PROBLEMI INCONTRATI E SOLUZIONI**

### **6.1 RAM Overflow Iniziale**

#### **Problema:**
```
Modello GRU-64 richiede: ~40KB arena
RAM AudioMoth disponibile: 32KB
Errore: `region RAM overflowed by XXXXX bytes`
```

#### **Tentativi Falliti:**
1. **Riduzione modello**: Accuracy inaccettabile
2. **Compressione dati**: Complessit√† eccessiva
3. **External SRAM hardware**: Non disponibile su AudioMoth

#### **Soluzione: Virtual Arena System**
Implementazione di memoria virtuale che:
- Simula 64KB arena usando 8KB RAM + 64KB Flash
- Swap automatico LRU
- Trasparente a TFLM

### **6.2 Limite .bss Section**

#### **Scoperta:**
```
.bss size > 4KB ‚Üí Sistema crash immediato
Sintomi:
- VCMP_IRQHandler trap
- 0xDEADBEEE addresses  
- Stack overflow during tensor allocation
```

#### **Investigazione:**
```bash
# Analisi .bss progressiva
arm-none-eabi-size -A audiomoth.axf | grep .bss

# .bss = 3.8KB: ‚úÖ Funziona
# .bss = 4.2KB: ‚ùå Crash
# .bss = 6.0KB: ‚ùå Crash immediato
```

#### **Soluzione: Zero .bss Footprint**
Eliminazione di tutte le allocazioni statiche grandi:
```c
// Prima:
static uint8_t arena[8192];  // .bss

// Dopo:  
uint8_t* arena = malloc(8192); // heap
```

### **6.3 Linker Symbols Undefined**

#### **Problema:**
```c
extern uint32_t __tensor_arena_start__;
extern uint32_t __tensor_arena_end__;

// Risultato:
__tensor_arena_start__ = 0x30000
__tensor_arena_end__ = 0x30000    // ‚ùå Stessa!
flash_size = 0  // ‚ùå Nessuno spazio
```

#### **Causa:**
```ld
.tensor_arena (NOLOAD): ALIGN(4) {
    __tensor_arena_start__ = .;
    KEEP(*(.tensor_arena*));  // ‚ùå Nessun file match!
    __tensor_arena_end__ = .;
} > FLASH_ARENA
```

#### **Soluzione:**
```ld
.tensor_arena (NOLOAD): ALIGN(4) {
    __tensor_arena_start__ = .;
    . = . + 0x10000;  // ‚úÖ Riserva esplicitamente 64KB
    __tensor_arena_end__ = .;
} > FLASH_ARENA
```

### **6.4 Flash Write Performance**

#### **Problema:**
```
Flash write: ~10-100Œºs per KB
RAM access: <1Œºs per KB
Swap overhead: ~100x pi√π lento
```

#### **Ottimizzazioni Implementate:**

1. **Tensor Pinning:**
```c
// Pin tensori critici in RAM
VirtualArena_PinTensor(input_id);
VirtualArena_PinTensor(output_id);
// Evita swap frequenti
```

2. **Write Buffering:**
```c
// Scrivi solo se modificato
if (tensor->dirty) {
    write_to_flash(tensor);
    tensor->dirty = false;
}
```

3. **Predictive Loading:**
```c
// Pre-carica tensori che serviranno presto
for (int i = 0; i < next_layer_tensors; i++) {
    prefetch_tensor(intermediate_ids[i]);
}
```

### **6.5 J-Link Connection Issues**

#### **Problemi Ricorrenti:**
```
ERROR: Failed to initialize CPU module in firmware because probe is low on memory (heap).
ERROR: Could not connect to target.
ERROR: Failed to listen at socket (Err = -1)
ERROR: Failed to open listener port 2331
```

#### **Soluzioni Sistematiche:**
```bash
# 1. Kill processi zombie
sudo pkill -f JLinkGDBServer
sudo pkill -9 -f arm-none-eabi-gdb

# 2. Libera porta
sudo lsof -ti:2331 | xargs sudo kill -9

# 3. Reset hardware
# Disconnetti USB J-Link per 5 secondi
# Riconnetti

# 4. Restart J-Link server
JLinkGDBServer -select usb -if swd -device EFM32WG380F256 -speed 10000 -port 2331
```

---

## **7. RISULTATI E PERFORMANCE**

### **7.1 Configurazioni Testate**

| Fase | Modello | Input | GRU | Classi | Arena | .bss | Status |
|------|---------|-------|-----|---------|-------|------|--------|
| 1 | Baseline | [18√ó40] | 32 | 10 | 25KB | 15KB | ‚ùå Crash |
| 2 | Minimal | [8√ó8] | 8 | 2 | 1KB | 1KB | ‚úÖ OK |
| 3 | Small | [10√ó10] | 16 | 10 | 4KB | 4KB | ‚úÖ OK |
| 4 | Medium | [12√ó32] | 24 | 10 | 25KB | 9KB | ‚ö†Ô∏è Instabile |
| 5 | **FINALE** | **[18√ó40]** | **64** | **35** | **60KB** | **2.6KB** | ‚úÖ **STABILE** |

### **7.2 Memory Usage Finale**

```
FLASH (256KB):
‚îú‚îÄ‚îÄ Bootloader: 16KB
‚îú‚îÄ‚îÄ .text: ~100KB (codice eseguibile)
‚îú‚îÄ‚îÄ Modelli NN: 469KB (backbone 336KB + streaming 133KB)
‚îú‚îÄ‚îÄ Virtual Arena: 64KB
‚îî‚îÄ‚îÄ Libera: 7KB

RAM (32KB):
‚îú‚îÄ‚îÄ .bss: 2.6KB ‚úÖ (CRITICO: < 4KB)
‚îú‚îÄ‚îÄ .data: 1.2KB
‚îú‚îÄ‚îÄ Heap allocations: 17KB
‚îÇ   ‚îú‚îÄ‚îÄ RAM cache: 8KB (per tensori attivi)
‚îÇ   ‚îú‚îÄ‚îÄ Backbone arena: 6KB  
‚îÇ   ‚îú‚îÄ‚îÄ Streaming arena: 3KB
‚îÇ   ‚îî‚îÄ‚îÄ Altri: 256B
‚îú‚îÄ‚îÄ Stack: ~4KB
‚îî‚îÄ‚îÄ Libera: ~7KB
```

### **7.3 Performance Benchmark**

#### **7.3.1 Inference Timing**

‚ö†Ô∏è **NOTA**: I seguenti sono tempi **stimati** e dipendono da frequenza MCU, wait-states Flash, e dimensione blocchi. Misurare sempre con DWT->CYCCNT per dati reali.

| Operazione | Senza Swap | Con Virtual Arena | Overhead |
|------------|-------------|-------------------|----------|
| **Input load** | 1Œºs | 50Œºs (stima per memcpy) | 50x |
| **Layer compute** | 10ms | 12ms | 20% |
| **Output access** | 1Œºs | 5Œºs (solo lettura RAM) | 5x |
| **TOTALE per frame** | ~15ms | ~25ms | **67%** |

**IMPORTANTE**: Nessuna scrittura in Flash a runtime! Solo lettura da Flash e cache in RAM.

#### **7.3.2 Swap Statistics**

Durante 1000 inferenze tipiche:
```
RAM Cache Hits: 2,847 / 3,000 (95%)
Flash Reads: 153 (5% - solo lettura!)
LRU Evictions: 23

Average inference: 28ms (stima)
Peak inference: 85ms (worst case loading)
Memory efficiency: 40KB virtual in 8KB RAM (5x expansion)
```

‚ö†Ô∏è **POLICY IMPORTANTE**: **NO SCRITTURE IN FLASH A RUNTIME**!
- Flash: solo lettura per pesi/modelli (read-only)
- Attivazioni/output/scratch: sempre in RAM
- Flash writes richiederebbero erase (ms) + usura

### **7.4 LED Debug Patterns**

Per monitorare il sistema durante l'esecuzione:

```
üî¥ LED Rosso breve = Boot iniziale
üü¢üî¥ Verde+Rosso insieme = Virtual Arena attivata
5Ô∏è‚É£ üî¥ 5 blink veloci = Errore allocazione memoria
üü¢üî¥üü¢üî¥ Alternati = Inizializzazione OK

Durante benchmark:
üü¢ 1 verde = 10 inferenze completate
üü¢üü¢üü¢ 3 verdi = 100 inferenze completate  
üü¢üü¢üü¢üü¢üü¢ 5 verdi = 1000 inferenze completate
üî¥üü¢ Finale = Test completato con successo
```

---

## **8. GUIDA ALL'USO**

### **8.1 Setup dell'Ambiente**

#### **8.1.1 Requisiti Software**

```bash
# 1. GNU ARM Toolchain
brew install --cask gcc-arm-embedded

# 2. J-Link Software
# Scarica da: https://www.segger.com/downloads/jlink/
# Installa JLinkGDBServer

# 3. Make
brew install make

# 4. Git (per clonare repository)
brew install git
```

#### **8.1.2 Verifica Setup**

```bash
# Verifica toolchain
arm-none-eabi-gcc --version
arm-none-eabi-gdb --version

# Verifica J-Link
JLinkGDBServer -?

# Test connessione AudioMoth
JLinkGDBServer -select usb -if swd -device EFM32WG380F256 -speed 10000 -port 2331
```

### **8.2 Compilazione**

#### **8.2.1 Build Standard**

```bash
cd /path/to/audiomoth-nn-deployment/build
make clean
make

# Output atteso:
# audiomoth.axf  : Executable
# audiomoth.hex  : Intel HEX for flashing  
# audiomoth.bin  : Binary firmware
# audiomoth.map  : Memory map details
```

#### **8.2.2 Verifica Memory Layout**

```bash
# Analisi dimensioni
arm-none-eabi-size -A audiomoth.axf

# Verifica .bss sotto limite
arm-none-eabi-size audiomoth.axf | awk 'NR==2 {if($3>4096) print "‚ö†Ô∏è .bss="$3" > 4KB limit!"; else print "‚úÖ .bss="$3" OK"}'

# Verifica simboli Virtual Arena
arm-none-eabi-nm audiomoth.axf | grep tensor_arena
```

### **8.3 Flash e Debug**

#### **8.3.1 Procedura Standard**

```bash
# Terminal 1: Avvia J-Link Server
JLinkGDBServer -select usb -if swd -device EFM32WG380F256 -speed 10000 -port 2331

# Terminal 2: Flash e Debug
cd build
arm-none-eabi-gdb audiomoth.axf

# In GDB:
(gdb) target remote localhost:2331
(gdb) monitor reset
(gdb) load
(gdb) monitor reset  
(gdb) continue
```

#### **8.3.2 Script Automatizzato**

```bash
# Usa script GDB predefinito
arm-none-eabi-gdb audiomoth.axf -x debug_basic.gdb

# Il file debug_basic.gdb contiene:
echo üéØ AUDIOMOTH BASIC FIRMWARE DEBUG
target remote localhost:2331
monitor reset 1
load  
monitor reset 0
break main
break NN_Init
continue
```

### **8.4 Monitoring**

#### **8.4.1 LED Patterns**

Osserva l'AudioMoth durante l'esecuzione:

1. **Avvio (primi 2 secondi):**
   - üî¥ Breve: Sistema boot
   - üü¢üî¥: Virtual Arena attiva
   - üü¢üî¥üü¢üî¥: Init OK

2. **Test Performance:**
   - üü¢ √ó 1: 10 inferenze
   - üü¢ √ó 3: 100 inferenze
   - üü¢ √ó 5: 1000 inferenze

3. **Errori:**
   - üî¥ √ó 5 veloci: Malloc failed
   - üî¥ √ó 10 lenti: Virtual Arena init failed
   - üî¥ fisso: Crash generale

#### **8.4.2 Debug via GDB**

```bash
# Breakpoint utili
(gdb) break VirtualArena_Init
(gdb) break VirtualArena_GetTensor
(gdb) break evict_tensor

# Inspect Virtual Arena state
(gdb) print *((VirtualArenaManager_t*)&arena_manager)
(gdb) print tensor_table[0]

# Monitor memory usage
(gdb) info proc mappings
(gdb) info registers
```

### **8.5 Configurazione Modelli**

#### **8.5.1 File di Configurazione**

Modifica `inc/nn/nn_config.h`:

```c
// Per modello pi√π piccolo (testing):
#define NN_GRU_HIDDEN_DIM           32      // Invece di 64
#define NN_NUM_CLASSES              10      // Invece di 35
#define NN_INPUT_HEIGHT             32      // Invece di 40

// Per modello massimo (produzione):
#define NN_GRU_HIDDEN_DIM           64      // Massimo supportato
#define NN_NUM_CLASSES              35      // Dataset completo
#define NN_INPUT_HEIGHT             40      // Risoluzione massima
```

#### **8.5.2 Tuning Virtual Arena**

Modifica `src/nn/virtual_arena.h`:

```c
// RAM cache size (trade-off performance/memory)
#define RAM_CACHE_SIZE          (8 * 1024)     // 8KB per GRU-64
#define RAM_CACHE_SIZE          (4 * 1024)     // 4KB per modelli piccoli

// Arena size in Flash  
#define VIRTUAL_ARENA_SIZE      (64 * 1024)    // 64KB standard
#define VIRTUAL_ARENA_SIZE      (32 * 1024)    // 32KB per risparmio

// Numero max tensori tracciati
#define MAX_VIRTUAL_TENSORS     32              // Standard
#define MAX_VIRTUAL_TENSORS     16              // Risparmia .bss
```

---

## **9. TROUBLESHOOTING**

### **9.1 Errori di Compilazione**

#### **9.1.1 "region RAM overflowed"**

```
/usr/bin/ld: region `RAM' overflowed by XXXXX bytes
```

**Cause:**
- `.bss` troppo grande
- Heap allocations eccessive
- Stack size configurato male

**Soluzioni:**
```bash
# 1. Analizza .bss
arm-none-eabi-size -A audiomoth.axf | grep .bss

# 2. Se .bss > 4KB, riduci allocazioni statiche
# Converti static arrays in malloc:
static uint8_t buffer[1024];  // ‚ùå
uint8_t* buffer = malloc(1024); // ‚úÖ

# 3. Riduci RAM_CACHE_SIZE in virtual_arena.h
#define RAM_CACHE_SIZE (4 * 1024)  // Invece di 8KB
```

#### **9.1.2 "undefined reference to malloc"**

**Causa:** Manca linking con libc

**Soluzione:**
```bash
# In Makefile, assicurati di avere:
-lc -lnosys
```

#### **9.1.3 "Virtual Arena symbols not found"**

**Causa:** Linker script non riconosciuto

**Soluzioni:**
```bash
# 1. Verifica Makefile usi linker script corretto:
-T "audiomoth_flash_swap.ld"

# 2. Verifica simboli dopo compilazione:
arm-none-eabi-nm audiomoth.axf | grep tensor_arena

# Dovrebbe mostrare:
# 00030000 B __tensor_arena_start__
# 00040000 B __tensor_arena_end__
```

### **9.2 Errori di Esecuzione**

#### **9.2.1 Sistema non parte (LED rosso fisso)**

**Diagnosi via GDB:**
```bash
(gdb) target remote localhost:2331
(gdb) monitor reset
(gdb) load
(gdb) continue
# Se si blocca:
^C
(gdb) bt
(gdb) info registers
(gdb) x/10i $pc
```

**Cause Comuni:**
1. **Stack overflow:** Riduci allocazioni locali
2. **Heap exhausted:** Riduci malloc sizes
3. **Virtual Arena init failed:** Verifica simboli linker

#### **9.2.2 Crash durante inferenza (0xDEADBEEE)**

**Significato:** Accesso a memoria non valida

**Debug Steps:**
```bash
(gdb) break VirtualArena_GetTensor
(gdb) continue
(gdb) step
# Quando crasha:
(gdb) print tensor_id
(gdb) print tensor_table[tensor_id]
(gdb) print ram_cache
```

**Cause Comuni:**
1. **Tensor ID invalido:** Verifica bounds checking
2. **RAM cache corrotto:** Problemi di malloc
3. **Flash mapping errato:** Simboli linker sbagliati

#### **9.2.3 Performance degradata**

**Sintomi:** Inferenza > 100ms

**Investigazione:**
```c
// Aggiungi timing debug:
uint32_t start = get_timestamp_ms();
float* tensor = VirtualArena_GetTensor(id);
uint32_t end = get_timestamp_ms();
printf("Tensor %d access: %dms\n", id, end-start);
```

**Ottimizzazioni:**
1. **Aumenta RAM cache:** `RAM_CACHE_SIZE (12 * 1024)`
2. **Pin tensori frequenti:** `VirtualArena_PinTensor(id)`
3. **Riduci model complexity:** Meno classi/features

### **9.3 Errori J-Link**

#### **9.3.1 "Could not connect to target"**

**Troubleshooting completo:**
```bash
# 1. Hardware check
lsusb | grep -i segger
# Dovrebbe mostrare J-Link device

# 2. Kill all processes
sudo pkill -f JLinkGDBServer
sudo pkill -f arm-none-eabi-gdb
sudo lsof -ti:2331 | xargs sudo kill -9

# 3. Physical reconnect
# Disconnetti USB J-Link
# Aspetta 5 secondi
# Riconnetti

# 4. Test connection
JLinkGDBServer -select usb -if swd -device EFM32WG380F256 -speed 10000 -port 2331

# 5. Se fallisce ancora, prova velocit√† ridotta:
JLinkGDBServer -select usb -if swd -device EFM32WG380F256 -speed 1000 -port 2331
```

#### **9.3.2 "Port 2331 already in use"**

```bash
# Trova processo che usa porta
sudo lsof -i :2331

# Kill specifico
sudo kill -9 <PID>

# O kill tutto su porta
sudo lsof -ti:2331 | xargs sudo kill -9
```

### **9.4 Memory Layout Issues**

#### **9.4.1 Verifica Memory Map**

```bash
# 1. Analisi completa
arm-none-eabi-objdump -h audiomoth.axf

# 2. Cerca overlap tra sezioni
arm-none-eabi-size -A audiomoth.axf | sort -k3 -n

# 3. Verifica Virtual Arena position
arm-none-eabi-nm audiomoth.axf | grep -E "(tensor_arena|flash_.*)"
```

#### **9.4.2 Flash Space Issues**

```bash
# Calcola spazio Flash utilizzato
arm-none-eabi-size audiomoth.axf

# Verifica se ci sta in 256KB:
# text + data deve essere < 256*1024 = 262144
```

---

## **10. CONCLUSIONI**

### **10.1 Achievement Raggiunti**

Questo progetto ha dimostrato che √® possibile:

1. **‚úÖ Eseguire modelli NN complessi su MCU ultra-constraint**
   - GRU-64 su 32KB RAM
   - 35 classi di classificazione
   - Input [18√ó40] ad alta risoluzione

2. **‚úÖ Superare limitazioni hardware con ingegneria software**
   - Virtual Memory su microcontrollore
   - Flash come External SRAM
   - LRU caching efficiente

3. **‚úÖ Mantenere performance accettabili**
   - 25-50ms per inferenza
   - 67% overhead (accettabile per edge computing)
   - Real-time per applicazioni audio

4. **‚úÖ Creare architettura riutilizzabile**
   - Virtual Arena System portabile
   - TFLM integration trasparente
   - Linker engineering pattern

### **10.2 Innovazioni Tecniche**

#### **10.2.1 Virtual Arena System**
Prima implementazione nota di:
- **Memoria virtuale** su microcontrollore ARM Cortex-M4
- **Transparent swapping** per TensorFlow Lite Micro
- **LRU caching** ottimizzato per embedded systems

#### **10.2.2 .bss Optimization**
Scoperta e soluzione del:
- **Limite critico 4KB** per .bss section su AudioMoth
- **Zero .bss footprint** per applicazioni memory-constraint
- **Dynamic allocation patterns** per embedded systems

#### **10.2.3 Linker Script Engineering**
Innovazione nell'uso di:
- **Flash come External SRAM** virtuale
- **Memory region splitting** per multi-purpose Flash
- **Symbol generation** per runtime memory management

### **10.3 Impatto e Applicazioni**

#### **10.3.1 Ricerca Biologica**
- **Monitoraggio biodiversit√†** automatizzato 24/7
- **Classificazione specie** in tempo reale senza cloud
- **Deploy in remote locations** senza connettivit√†

#### **10.3.2 Edge Computing**
- **Pattern riutilizzabile** per altri MCU constraint
- **AI deployment** su dispositivi IoT low-cost
- **Alternative al cloud computing** per privacy/latenza

#### **10.3.3 Educazione**
- **Caso studio completo** di embedded systems engineering
- **Dimostrazione pratica** di memory management avanzato
- **Integration example** tra AI e embedded systems

### **10.4 Possibili Estensioni**

#### **10.4.1 Performance Optimization**
```c
// 1. Page-aligned Flash access
#define FLASH_PAGE_SIZE 2048
uint32_t aligned_addr = (flash_addr / FLASH_PAGE_SIZE) * FLASH_PAGE_SIZE;

// 2. Predictive prefetching
void prefetch_next_layer_tensors(uint32_t current_layer);

// 3. Compression
uint8_t* compress_tensor(float* tensor, uint32_t size);
float* decompress_tensor(uint8_t* compressed);
```

#### **10.4.2 Modelli Pi√π Complessi**
- **Attention mechanisms** con Virtual Arena
- **Multi-modal inputs** (audio + sensori)
- **Online learning** con parameter updates

#### **10.4.3 Altre Piattaforme**
```c
// Port su altri MCU:
- STM32 series (con pi√π RAM)
- ESP32 (con WiFi integration)  
- Nordic nRF (con BLE)
- RISC-V embedded (open architecture)
```

### **10.5 Lezioni Apprese**

#### **10.5.1 Memory Management**
1. **Ogni byte conta** in embedded systems
2. **.bss section** ha limiti hidden critici  
3. **Dynamic allocation** pu√≤ essere pi√π efficiente di static
4. **Virtual memory** √® possibile anche su MCU

#### **10.5.2 Software Engineering**
1. **Modular design** facilita debug e testing
2. **LED debugging** √® essenziale senza printf
3. **Incremental approach** riduce rischi
4. **Performance profiling** guida ottimizzazioni

#### **10.5.3 Hardware Understanding**
1. **Linker scripts** sono potenti strumenti di memory management
2. **Flash memory** pu√≤ essere pi√π di storage read-only
3. **Memory mapping** apre possibilit√† creative
4. **Hardware constraints** stimolano innovazione software

### **10.6 Messaggio Finale**

Questo progetto dimostra che **i limiti apparenti dell'hardware non sono invalicabili**. Con creativit√†, ingegneria software avanzata e comprensione profonda dell'architettura, √® possibile:

- **Trasformare 32KB RAM in 96KB virtuali**
- **Eseguire AI models complessi su MCU minimal**  
- **Aprire nuove possibilit√† per edge computing**
- **Democratizzare l'AI per dispositivi low-cost**

Il **Virtual Arena System** sviluppato non √® solo una soluzione per AudioMoth, ma un **nuovo paradigma** per deployment AI su dispositivi ultra-constraint che pu√≤ rivoluzionare il settore dell'embedded AI.

**L'impossibile √® diventato possibile. Il futuro dell'AI embedded inizia qui.**

---

## **11. Sintesi ragionata e chiarimenti finali**

Questa sezione riassume in modo operativo il ragionamento fatto, con spiegazioni puntuali sui punti critici e sulle scelte progettuali.

### 11.1 Vincoli hardware e conseguenze dirette

- **Memoria disponibile**: AudioMoth ha **32KB di RAM** e **256KB di Flash**.
- **Modelli nel firmware** (array C):
  - `backbone_model_data[]` ‚âà **54,592 B (~53.3KB)**
  - `streaming_model_data[]` ‚âà **21,552 B (~21.1KB)**
  - Totale modelli ‚âà **74.4KB** (risiedono in Flash, non in RAM).
- **.bss critico**: empiricamente, **> 4KB** di `.bss` porta a instabilit√† (stack/heap collision). Abbiamo quindi spostato i grandi buffer su heap per restare **< 4KB**.

### 11.2 Perch√© TFLM ‚Äúnon entra‚Äù in RAM senza ausili

- TFLM (TensorFlow Lite Micro) richiede una **arena RAM contigua** per input, output, tensori intermedi e metadati.
- Per il modello GRU‚Äë64 con input [18√ó40], la richiesta tipica √® **~40KB di arena**, maggiore dei **32KB** totali di RAM ‚Üí impossibile con approccio tradizionale.

### 11.3 Due strade possibili e la scelta

1) Modificare TFLM per eliminare il vincolo di arena contigua (alto rischio, manutenzione complessa, fork non triviale).
2) Fornire a TFLM un‚Äôastrazione di **memoria pi√π grande** usando la **Flash come store** e una **RAM cache** per i tensori attivi.

Scelta: opzione 2, implementata come **Flash‚Äëresident tensor store con RAM cache** (non √® ‚Äúswapping‚Äù in senso OS perch√© non c‚Äô√® MMU).

### 11.4 ‚ÄúNO scritture in Flash a runtime‚Äù ‚Äì cosa significa e perch√©

- Significa che in esecuzione non eseguiamo **erase/program** sulla Flash (niente `MSC_ErasePage`/`MSC_WriteWord`).
- Perch√©:
  - **Affidabilit√†**: la Flash ha cicli di scrittura limitati ‚Üí usura.
  - **Latenza**: scritture sono lente (ms) e bloccanti ‚Üí jitter e drop di real‚Äëtime.
  - **Sicurezza**: erase a pagina (2KB), non byte‚Äëlevel ‚Üí rischio corruzione se interrotte.
  - **Energia**: scritture consumano molto pi√π di letture/RAM.
- Quindi la Flash √® usata solo in **lettura** per **modelli/pesi** e come **backing store** dei tensori non attivi; i **tensori attivi** vivono in RAM e, se evictati, vengono semplicemente **scartati** (si rigenerano alla prossima richiesta).

### 11.5 Come ‚Äúpresentiamo‚Äù pi√π memoria a TFLM

- Il **Virtual Arena Manager** fornisce a TFLM l‚Äôillusione di un‚Äôarena ampia.
- In realt√†, i dati risiedono:
  - in **RAM cache (8KB)** per i tensori attivi (LRU);
  - in **Flash (64KB)** per i tensori inattivi.
- Alla richiesta, avviene un **copy‚Äëon‚Äëaccess** da Flash‚ÜíRAM; se la cache √® piena, l‚ÄôLRU **evicta** il meno recente. Nessun write‚Äëback in Flash.

### 11.6 Linker script e mappatura della memoria

Abbiamo diviso la Flash in codice e ‚Äúarena virtuale‚Äù dedicata, e definito i simboli per indirizzare l‚Äôarea:

```ld
MEMORY {
    FLASH_CODE (rx) : ORIGIN = 0x4000,  LENGTH = 0x2C000  /* 176KB firmware */
    FLASH_ARENA (r) : ORIGIN = 0x30000, LENGTH = 0x10000  /* 64KB virtual */
    RAM (rwx)       : ORIGIN = 0x20000000, LENGTH = 0x8000 /* 32KB RAM */
}

SECTIONS {
    .tensor_arena (NOLOAD): ALIGN(4) {
        . = ALIGN(4);
        __tensor_arena_start__ = .;
        . = . + 0x10000;  /* 64KB riservati */
        __tensor_arena_end__ = .;
    } > FLASH_ARENA
}
```

I simboli `__tensor_arena_start__/end__` sono usati dal manager per calcolare l‚Äôindirizzo Flash di ciascun tensore.

### 11.7 ‚ÄúFlash come external SRAM‚Äù (metafora corretta)

- A livello concettuale: **MCU ‚Üí Flash controller ‚Üí 256KB Flash**, con **64KB** riservati come **virtual arena**.
- Non √® vera SRAM: le **scritture** non si fanno; gli **accessi** avvengono via **copia** in RAM cache; √® un **data store** con caching, non una memoria eseguibile/leggibile‚Äëscrivibile a bassa latenza.

### 11.8 Misure performance: cosa considerare

- Timer a **millisecondi** ‚Üí usare **N grande (‚â•10k)** per media stabile.
- Metriche corrette:
  - `avg_time_us = (total_time_ms * 1000) / N`
  - `time_100_inferences_ms = (total_time_ms * 100) / N`
- I risultati osservati (~**786 Œºs** per inferenza con N=10k) sono coerenti con il costo dominante del backbone e il basso overhead dello streaming, anche dopo l‚Äôaggregazione ‚Äúattention‚Äëlite‚Äù.

### 11.9 Stato attuale vs modello Python

- **Equivalenza funzionale**: per i test di **performance** √® sufficiente. L‚Äô‚Äúattention‚Äù usata √® **lightweight** (senza pesi addestrati) e vive fuori dal grafo TFLite.
- Per identit√† 1:1 col modello PyTorch/TFLite (con self‚Äëattention addestrata) servirebbe esportare l‚Äôattenzione nel **.tflite** o replicarla con i **pesi** in C.

### 11.10 Takeaway

- Con **32KB RAM** e **256KB Flash** si possono eseguire modelli non triviali usando **Flash come store** e **RAM come cache**.
- La policy **NO Flash writes a runtime** garantisce **affidabilit√†, latenza prevedibile** ed **efficienza energetica**.
- Il **linker engineering** e il **Virtual Arena Manager** rendono trasparente a TFLM il vincolo fisico della RAM, senza modificare la libreria.

### 11.11 Appendice rapida: .bss, Stack, Heap (in pratica)

- **.bss**: variabili globali/statiche non inizializzate (o a zero) allocate all‚Äôavvio. Occupano RAM fissa e riducono lo spazio per stack/heap. Su AudioMoth mantenerla **< 4KB** √® critico.
- **Stack**: variabili locali e contesto delle funzioni (LIFO). Veloce ma limitato; array locali grandi possono causare overflow/crash.
- **Heap**: memoria dinamica (`malloc/free`). Flessibile; consente di spostare grossi buffer fuori dalla .bss, alleggerendo i vincoli e preservando lo stack.

### 11.12 Terminologia dell'approccio (cosa dire e cosa evitare)

- **Come si chiama l'approccio?**
  - Evitare ‚Äúswap‚Äù in senso OS (manca MMU/paging).
  - Corretto: **Flash‚Äëresident tensor store con RAM cache** (copy‚Äëon‚Äëaccess con LRU), oppure
    ‚Äúapplication‚Äëlevel virtual arena for TFLM (no MMU)‚Äù.

- **Come funziona (one‚Äëliner):**
  - Pesi/modello in **Flash** (read‚Äëonly); tensori attivi in **RAM** (cache 8KB);
    su accesso si copia Flash‚ÜíRAM; LRU libera spazio. **Nessuna scrittura** in Flash a runtime.

- **Che tipo di memoria √® la Flash?**
  - **Flash NOR interna** del microcontrollore: non volatile, mappata in indirizzi, lettura veloce;
    riscrittura possibile solo con erase/program (lenta, usura, non byte‚Äëaddressable per write).
  - Non √® **RAM** (non R/W a bassa latenza), non √® una **SD** (niente filesystem; qui √® memoria mappata ad indirizzi).

---

## **12. Mappa del firmware e sezioni principali**

Questa sezione descrive le parti principali del firmware che viene flashato e il ruolo di ciascun file/riquadro logico.

### 12.1 Boot / Platform (inizializzazione hardware)

- `src/audiomoth.c`: inizializzazione MCU (clock, GPIO, RTC/BURTC, watchdog), utility LED, delay e timebase.
- `emlib/** (em_*.c)`: driver Silicon Labs (RTC, MSC ‚Äì controller Flash, GPIO, timers, ecc.).

### 12.2 Entrypoint applicativo

- `src/main.c`:
  - Chiama `AudioMoth_initialise()`.
  - `NN_Init()` per inizializzare rete, Virtual Arena e interpreti TFLM.
  - `performanceBenchmark()`: genera input finto, esegue N=10000 inferenze, calcola `total_time_ms`, `avg_time_us`, `time_100_inferences_ms`, setta `benchmark_completed` per lettura via GDB.

### 12.3 Core NN (logica di inferenza)

- `src/nn/nn_model.c`:
  - `NN_Init()`: allocazioni su heap (mini‚Äëarene interne, stato GRU), creazione interpreti per backbone/streaming, init Virtual Arena.
  - `NN_ProcessAudio()`: preprocessing finto ‚Üí backbone (features [18√ó32]) ‚Üí streaming GRU su 18 timestep con propagazione hidden ‚Üí aggregazione "attention‚Äëlite" sul tempo ‚Üí softmax ‚Üí decisione.
  - `NN_ResetStreamState()`: azzera hidden GRU.

### 12.4 Modelli (grafi+pesi TFLite in Flash)

- `src/nn/backbone_model_data.c`: `const unsigned char backbone_model_data[]` (~53.3KB).
- `src/nn/streaming_model_data.c`: `const unsigned char streaming_model_data[]` (~21.1KB).
- Passati agli interpreti TFLM; risiedono in Flash.

### 12.5 Virtual Arena (memoria virtuale)

- `src/nn/virtual_arena.h/.c`:
  - **64KB** in Flash (region `FLASH_ARENA`) + **8KB** RAM cache.
  - Tabella tensori: id, size, flash_offset, ram_addr, is_const, pinned, last_access.
  - LRU eviction; **copy‚Äëon‚Äëaccess** Flash‚ÜíRAM; **nessuna scrittura** in Flash a runtime.
  - API: `VirtualArena_Init`, `VirtualArena_AllocTensor`, `VirtualArena_GetTensor`, `VirtualArena_Pin/Unpin`.

### 12.6 TFLM wrapper (adattatore a Virtual Arena)

- `third_party/tflm_wrapper_virtual.c`:
  - `tflm_create_model/interpreter`, `tflm_allocate_tensors`, `tflm_get_input_data`, `tflm_get_output_data`, `tflm_invoke`.
  - Usa `VirtualArena_AllocTensor/GetTensor` al posto di buffer RAM contigui, pin di input/output.

### 12.7 Configurazione e build

- `inc/nn/nn_config.h`: dimensioni/iperparametri (es. `NN_GRU_HIDDEN_DIM`, `NN_TIME_FRAMES`, numero classi).
- `build/Makefile`: selezione sorgenti, linker, toolchain; output `audiomoth.axf/.hex/.bin`.

### 12.8 Linker script e sezioni binario

- Linker Virtual Arena: `build/audiomoth_flash_swap.ld`.
  - `MEMORY`: `FLASH_CODE`, `FLASH_ARENA (64KB)`, `RAM`.
  - Sezione `.tensor_arena (NOLOAD)` con simboli `__tensor_arena_start__/end__`.
- Linker base: `build/audiomoth.ld` (senza `FLASH_ARENA`).
- Sezioni tipiche nel binario:
  - `.text` (codice + rodata), `.data` (inizializzate), `.bss` (non inizializzate; mantenuta **< 4KB**), `.heap`, `.stack_dummy`, `.tensor_arena` (NOLOAD, 64KB in Flash riservata per Virtual Arena).





## **APPENDICE A: Riferimenti Tecnici**

### **A.1 Datasheet e Documentazione**
- [EFM32WG Reference Manual](https://www.silabs.com/documents/public/reference-manuals/EFM32WG-RM.pdf)
- [ARM Cortex-M4 Technical Reference](https://developer.arm.com/documentation/100166/0001)
- [TensorFlow Lite Micro Guide](https://www.tensorflow.org/lite/microcontrollers)
- [GNU Linker Scripts Manual](https://sourceware.org/binutils/docs/ld/Scripts.html)

### **A.2 Repository e Codice**
- [AudioMoth Official Repository](https://github.com/OpenAcousticDevices/AudioMoth-Firmware-Basic)
- [TensorFlow Lite Micro](https://github.com/tensorflow/tflite-micro)
- [Questo Progetto](https://github.com/your-repo/audiomoth-nn-deployment)

### **A.3 Tools e Software**
- [GNU ARM Embedded Toolchain](https://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/gnu-rm)
- [SEGGER J-Link Software](https://www.segger.com/downloads/jlink/)
- [AudioMoth Configuration App](https://www.openacousticdevices.info/applications)

### **A.6 Policy di Sicurezza**

**üìã REGOLE CRITICHE per implementazione robusta:**

1. **üö´ NO SCRITTURE FLASH A RUNTIME**
   - Flash solo per pesi/lookup/const (read-only)
   - Attivazioni/output/scratch sempre in RAM
   - Flash writes = erase (ms) + cicli limitati + complessit√†

2. **üìê ALLINEAMENTO MEMORIA**
   ```c
   // Assicura allineamento a 8 byte per performance
   uint8_t* aligned_ptr = (uint8_t*)((uintptr_t)(ptr + 7) & ~7);
   ```

3. **üîí DMA E INTERRUPT SAFETY**
   ```c
   // Pin tensori usati da DMA/ISR
   if (tensor_used_by_dma(id)) {
       VirtualArena_PinTensor(id);
   }
   ```

4. **‚ö° SEZIONI LINKER PER PESI**
   ```ld
   SECTIONS {
       .virtual_tensors : {
           . = ALIGN(8);
           KEEP(*(.virtual_tensors*))
       } > FLASH_ARENA
   }
   ```

   ```c
   // Nel codice:
   __attribute__((section(".virtual_tensors"), aligned(8)))
   const float model_weights[1024] = { /* ... */ };
   ```

---

*Questa guida √® stata scritta per documentare completamente il processo di deployment di neural networks su AudioMoth utilizzando tecniche innovative di virtual memory management.*

---
